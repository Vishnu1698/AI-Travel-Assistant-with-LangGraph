{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f0fb91cc",
      "metadata": {
        "id": "f0fb91cc"
      },
      "source": [
        "# AI Travel Agent Setup\n",
        "\n",
        "This notebook sets up and runs the AI Travel Agent application in Google Colab. Follow the steps below:\n",
        "\n",
        "1. Install dependencies.\n",
        "2. Set environment variables for SerpAPI and SendGrid.\n",
        "3. Write the `travel_app.py` script to disk.\n",
        "4. Launch the Streamlit app and open it via a public URL.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69dc0abc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69dc0abc",
        "outputId": "a3cb44e6-6adb-4705-c5f5-520258c8bddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.60)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.19-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.8-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting sendgrid\n",
            "  Downloading sendgrid-6.12.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting serpapi\n",
            "  Downloading serpapi-0.1.5-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (5.10.4)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (0.3.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.13.2)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.11.4)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-0.3.63-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.81.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Collecting langgraph-checkpoint>=2.0.26 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Collecting python-http-client>=3.2.1 (from sendgrid)\n",
            "  Downloading python_http_client-3.3.7-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting ecdsa<1,>=0.19.1 (from sendgrid)\n",
            "  Downloading ecdsa-0.19.1-py2.py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: werkzeug>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from sendgrid) (3.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from serpapi) (2.32.3)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat) (5.7.2)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.11/dist-packages (from nbformat) (5.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.40.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from ecdsa<1,>=0.19.1->sendgrid) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat) (0.25.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.8)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint>=2.0.26->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->serpapi) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->serpapi) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->serpapi) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->serpapi) (2025.4.26)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=2.2.0->sendgrid) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading langchain_openai-0.3.19-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.63-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.5/438.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.4.8-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sendgrid-6.12.3-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.1/102.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading serpapi-0.1.5-py2.py3-none-any.whl (10 kB)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ecdsa-0.19.1-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.26-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.2.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_http_client-3.3.7-py3-none-any.whl (8.4 kB)\n",
            "Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, python-http-client, python-dotenv, ormsgpack, ecdsa, serpapi, sendgrid, pydeck, langgraph-sdk, langchain-core, streamlit, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.60\n",
            "    Uninstalling langchain-core-0.3.60:\n",
            "      Successfully uninstalled langchain-core-0.3.60\n",
            "Successfully installed ecdsa-0.19.1 langchain-core-0.3.63 langchain-openai-0.3.19 langgraph-0.4.8 langgraph-checkpoint-2.0.26 langgraph-prebuilt-0.2.2 langgraph-sdk-0.1.70 ormsgpack-1.10.0 pydeck-0.9.1 python-dotenv-1.1.0 python-http-client-3.3.7 sendgrid-6.12.3 serpapi-0.1.5 streamlit-1.45.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv langchain-core langchain-openai langgraph sendgrid serpapi streamlit nbformat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fdf45e7",
      "metadata": {
        "id": "4fdf45e7"
      },
      "source": [
        "## 2. Set Environment Variables\n",
        "\n",
        "Replace the placeholder strings with your actual API keys and verified email addresses. Run the following cell to set the environment variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93144fb5",
      "metadata": {
        "id": "93144fb5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "\n",
        "# Replace the following placeholder values with your own credentials\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"\"\n",
        "os.environ[\"SENDGRID_API_KEY\"] = \"\"\n",
        "os.environ[\"FROM_EMAIL\"] = \"raj.dandekar8@gmail.com\"\n",
        "os.environ[\"TO_EMAIL\"] = \"hello@vizuara.com\"\n",
        "os.environ[\"EMAIL_SUBJECT\"] = \"Travel Information\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96f07d08",
      "metadata": {
        "id": "96f07d08"
      },
      "source": [
        "## 3. Write the `travel_app.py` Script\n",
        "\n",
        "The following cell writes the complete `travel_app.py` file to `/mnt/data/travel_app.py`. This script contains the Streamlit application, the agent logic, and the tool definitions.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# pylint: disable = http-used,print-used,no-self-use,invalid-name\n",
        "import datetime\n",
        "import operator\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "from typing import Annotated, TypedDict, Optional\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.messages import AnyMessage, HumanMessage, SystemMessage, ToolMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import END, StateGraph\n",
        "from sendgrid import SendGridAPIClient\n",
        "from sendgrid.helpers.mail import Mail\n",
        "import serpapi\n",
        "\n",
        "# Tool definitions\n",
        "from langchain.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# Load environment variables from a .env file\n",
        "_ = load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGP_nv1pd765",
        "outputId": "23ed3628-72d4-49f9-cbfb-5086b529b1a2"
      },
      "id": "wGP_nv1pd765",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CURRENT_YEAR = datetime.datetime.now().year\n"
      ],
      "metadata": {
        "id": "fPOofipId9JB"
      },
      "id": "fPOofipId9JB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], operator.add]\n",
        "\n",
        "\n",
        "TOOLS_SYSTEM_PROMPT = f\"\"\"You are a smart travel agency. Use the tools to look up information.\n",
        "You are allowed to make multiple calls (either together or in sequence).\n",
        "Only look up information when you are sure of what you want.\n",
        "The current year is {CURRENT_YEAR}. If you don't get flights, try searching till you find them!\n",
        "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
        "In your output, include links to hotel websites and flight websites (if possible),\n",
        "the logo of the hotel and the logo of the airline company (if possible),\n",
        "and always include both the price of the flight and the price of the hotel (with currency).\n",
        "For example, for hotels:\n",
        "    Rate: $581 per night\n",
        "    Total: $3,488\n",
        "\"\"\"\n",
        "\n",
        "# ----- Flights tool -----\n",
        "class FlightsInput(BaseModel):\n",
        "    departure_airport: Optional[str] = Field(description='Departure airport code (IATA)')\n",
        "    arrival_airport: Optional[str]   = Field(description='Arrival airport code (IATA)')\n",
        "    outbound_date: Optional[str]      = Field(description='Outbound date (YYYY-MM-DD)')\n",
        "    return_date: Optional[str]        = Field(description='Return date (YYYY-MM-DD)')\n",
        "    adults: Optional[int] = Field(1, description='Number of adults (default 1)')\n",
        "    children: Optional[int] = Field(0, description='Number of children (default 0)')\n",
        "    infants_in_seat: Optional[int] = Field(0, description='Number of infants in seat (default 0)')\n",
        "    infants_on_lap: Optional[int]   = Field(0, description='Number of infants on lap (default 0)')\n",
        "\n",
        "class FlightsInputSchema(BaseModel):\n",
        "    params: FlightsInput\n",
        "\n",
        "@tool(args_schema=FlightsInputSchema)\n",
        "def flights_finder(params: FlightsInput):\n",
        "    \"\"\"\n",
        "    Find flights using the Google Flights engine (via SerpAPI).\n",
        "    Returns:\n",
        "        dict or str: Flight search results or error message.\n",
        "    \"\"\"\n",
        "    query = {\n",
        "        'api_key': os.environ.get('SERPAPI_API_KEY'),\n",
        "        'engine': 'google_flights',\n",
        "        'hl': 'en',\n",
        "        'gl': 'us',\n",
        "        'departure_id': params.departure_airport,\n",
        "        'arrival_id': params.arrival_airport,\n",
        "        'outbound_date': params.outbound_date,\n",
        "        'return_date': params.return_date,\n",
        "        'currency': 'USD',\n",
        "        'adults': params.adults,\n",
        "        'infants_in_seat': params.infants_in_seat,\n",
        "        'stops': '1',\n",
        "        'infants_on_lap': params.infants_on_lap,\n",
        "        'children': params.children\n",
        "    }\n",
        "    try:\n",
        "        search = serpapi.search(query)\n",
        "        return search.data['best_flights']\n",
        "    except Exception as e:\n",
        "        return str(e)"
      ],
      "metadata": {
        "id": "lMzGDTiqd_DO"
      },
      "id": "lMzGDTiqd_DO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- Hotels tool -----\n",
        "class HotelsInput(BaseModel):\n",
        "    q: str = Field(description='Location for hotels (e.g., \"New York\")')\n",
        "    check_in_date: str  = Field(description='Check-in date (YYYY-MM-DD)')\n",
        "    check_out_date: str = Field(description='Check-out date (YYYY-MM-DD)')\n",
        "    sort_by: Optional[str] = Field(8, description='Sorting parameter (default=8 for rating)')\n",
        "    adults: Optional[int]   = Field(1, description='Number of adults (default 1)')\n",
        "    children: Optional[int] = Field(0, description='Number of children (default 0)')\n",
        "    rooms: Optional[int]    = Field(1, description='Number of rooms (default 1)')\n",
        "    hotel_class: Optional[str] = Field(None, description='Filter by hotel class (e.g., \"3\" or \"4\")')\n",
        "\n",
        "class HotelsInputSchema(BaseModel):\n",
        "    params: HotelsInput\n",
        "\n",
        "@tool(args_schema=HotelsInputSchema)\n",
        "def hotels_finder(params: HotelsInput):\n",
        "    \"\"\"\n",
        "    Find hotels using the Google Hotels engine (via SerpAPI).\n",
        "    Returns:\n",
        "        list or str: Up to 5 hotel property dicts or error message.\n",
        "    \"\"\"\n",
        "    query = {\n",
        "        'api_key': os.environ.get('SERPAPI_API_KEY'),\n",
        "        'engine': 'google_hotels',\n",
        "        'hl': 'en',\n",
        "        'gl': 'us',\n",
        "        'q': params.q,\n",
        "        'check_in_date': params.check_in_date,\n",
        "        'check_out_date': params.check_out_date,\n",
        "        'currency': 'USD',\n",
        "        'adults': params.adults,\n",
        "        'children': params.children,\n",
        "        'rooms': params.rooms,\n",
        "        'sort_by': params.sort_by,\n",
        "        'hotel_class': params.hotel_class\n",
        "    }\n",
        "    try:\n",
        "        search = serpapi.search(query)\n",
        "        data = search.data\n",
        "        return data['properties'][:5]\n",
        "    except Exception as e:\n",
        "        return str(e)\n"
      ],
      "metadata": {
        "id": "Ej-qjHSYeHwa"
      },
      "id": "Ej-qjHSYeHwa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOOLS = [flights_finder, hotels_finder]"
      ],
      "metadata": {
        "id": "lXuDw9F2eKkn"
      },
      "id": "lXuDw9F2eKkn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMAILS_SYSTEM_PROMPT = \"\"\"Your task is to convert structured markdown-like text into a valid HTML email body.\n",
        "- Do not include a ```html preamble in your response.\n",
        "- The output should be proper HTML, ready to be used as an email body.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MzPVN4oreMku"
      },
      "id": "MzPVN4oreMku",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6f25475",
      "metadata": {
        "id": "f6f25475"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Agent:\n",
        "    def __init__(self):\n",
        "        # Map name → tool function\n",
        "        self._tools = {t.name: t for t in TOOLS}\n",
        "        # A ChatOpenAI instance bound to both tools\n",
        "        self._tools_llm = ChatOpenAI(model='gpt-4o').bind_tools(TOOLS)\n",
        "\n",
        "        # Build the LangGraph state machine\n",
        "        builder = StateGraph(AgentState)\n",
        "        builder.add_node('call_tools_llm', self.call_tools_llm)\n",
        "        builder.add_node('invoke_tools', self.invoke_tools)\n",
        "        builder.add_node('email_sender', self.email_sender)\n",
        "        builder.set_entry_point('call_tools_llm')\n",
        "\n",
        "        # If the LLM's last message has no tool calls → go to email_sender\n",
        "        builder.add_conditional_edges(\n",
        "            'call_tools_llm',\n",
        "            Agent.exists_action,\n",
        "            {'more_tools': 'invoke_tools', 'email_sender': 'email_sender'}\n",
        "        )\n",
        "        builder.add_edge('invoke_tools', 'call_tools_llm')\n",
        "        builder.add_edge('email_sender', END)\n",
        "\n",
        "        memory = MemorySaver()\n",
        "        self.graph = builder.compile(checkpointer=memory, interrupt_before=['email_sender'])\n",
        "\n",
        "    @staticmethod\n",
        "    def exists_action(state: AgentState):\n",
        "        # If the last LLM response contains no tool_calls, move to email_sender\n",
        "        result = state['messages'][-1]\n",
        "        if len(result.tool_calls) == 0:\n",
        "            return 'email_sender'\n",
        "        return 'more_tools'\n",
        "\n",
        "    def call_tools_llm(self, state: AgentState):\n",
        "        # Prepend our system prompt, then ask the LLM to pick which tools to call\n",
        "        messages = state['messages']\n",
        "        messages = [SystemMessage(content=TOOLS_SYSTEM_PROMPT)] + messages\n",
        "        message = self._tools_llm.invoke(messages)\n",
        "        return {'messages': [message]}\n",
        "\n",
        "    def invoke_tools(self, state: AgentState):\n",
        "        # Execute each requested tool and wrap results in ToolMessages\n",
        "        tool_calls = state['messages'][-1].tool_calls\n",
        "        results = []\n",
        "        for t in tool_calls:\n",
        "            if t['name'] not in self._tools:\n",
        "                results.append(\n",
        "                    ToolMessage(tool_call_id=t['id'], name=t['name'], content=\"Bad tool name\")\n",
        "                )\n",
        "            else:\n",
        "                result = self._tools[t['name']].invoke(t['args'])\n",
        "                results.append(\n",
        "                    ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result))\n",
        "                )\n",
        "        return {'messages': results}\n",
        "\n",
        "    def email_sender(self, state: AgentState):\n",
        "        # (We won't actually use this node for Gradio; see below.)\n",
        "        return {'messages': []}\n",
        "\n",
        "\n",
        "# ===== 3) Helper function to send email via SendGrid =====\n",
        "\n",
        "def send_html_email(travel_html: str, sender: str, receiver: str, subject: str) -> str:\n",
        "    \"\"\"\n",
        "    Uses SendGrid to send travel_html as the email body.\n",
        "    Returns a status string.\n",
        "    \"\"\"\n",
        "    message = Mail(\n",
        "        from_email=sender,\n",
        "        to_emails=receiver,\n",
        "        subject=subject,\n",
        "        html_content=travel_html\n",
        "    )\n",
        "    try:\n",
        "        sg = SendGridAPIClient(os.environ.get('SENDGRID_API_KEY'))\n",
        "        resp = sg.send(message)\n",
        "        return f\"Email sent (status {resp.status_code})\"\n",
        "    except Exception as e:\n",
        "        return f\"Error sending email: {e}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 4) Instantiate a single global Agent =====\n",
        "\n",
        "agent = Agent()"
      ],
      "metadata": {
        "id": "Qiqas247ht94"
      },
      "id": "Qiqas247ht94",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 5) Gradio callables =====\n",
        "\n",
        "def process_query_gradio(user_query: str) -> str:\n",
        "    \"\"\"\n",
        "    Run the agent on the given travel query string, return the final text output.\n",
        "    \"\"\"\n",
        "    thread_id = str(uuid.uuid4())\n",
        "    # Create a single HumanMessage containing the entire query\n",
        "    messages = [HumanMessage(content=user_query)]\n",
        "    config = {'configurable': {'thread_id': thread_id}}\n",
        "\n",
        "    result = agent.graph.invoke({'messages': messages}, config=config)\n",
        "    # The agent’s final response (no further tool calls) is the last message’s .content\n",
        "    return result['messages'][-1].content\n"
      ],
      "metadata": {
        "id": "gyDcXkSXiLNq"
      },
      "id": "gyDcXkSXiLNq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_email_gradio(travel_info: str, sender: str, receiver: str, subject: str) -> str:\n",
        "    \"\"\"\n",
        "    Take the travel_info (HTML or plain text from the agent),\n",
        "    plus sender/receiver/subject, and send via SendGrid.\n",
        "    \"\"\"\n",
        "    if not sender or not receiver or not subject or not travel_info:\n",
        "        return \"Error: All fields are required.\"\n",
        "    return send_html_email(travel_info, sender, receiver, subject)"
      ],
      "metadata": {
        "id": "rpOBiOreiL4j"
      },
      "id": "rpOBiOreiL4j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 6) Build the Gradio Interface =====\n",
        "!pip install gradio\n",
        "import gradio as gr\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# ✈️🌍 AI Travel Agent (Gradio Edition)\")\n",
        "    gr.Markdown(\"Enter a travel query below (e.g. “Flights from New York to London June 10–15, and 4-star hotels”).\")\n",
        "\n",
        "    # Textbox to accept the user’s travel query\n",
        "    query_input = gr.Textbox(lines=3, placeholder=\"Type your travel query here…\", label=\"Travel Query\")\n",
        "    query_button = gr.Button(\"Get Travel Information\")\n",
        "    travel_output = gr.Markdown(\"\", label=\"Travel Info (Agent’s Response)\")\n",
        "\n",
        "    # When clicked, run process_query_gradio and show result in travel_output\n",
        "    query_button.click(fn=process_query_gradio, inputs=query_input, outputs=travel_output)\n",
        "\n",
        "    gr.Markdown(\"---\\n## Send the Above Info via Email\")\n",
        "    gr.Markdown(\"Enter sender, receiver, and subject. The email body will be exactly what the agent printed above.\")\n",
        "    sender_input   = gr.Textbox(label=\"Sender Email\")\n",
        "    receiver_input = gr.Textbox(label=\"Receiver Email\")\n",
        "    subject_input  = gr.Textbox(label=\"Subject\", value=\"Travel Information\")\n",
        "    email_button   = gr.Button(\"Send Email\")\n",
        "    email_status   = gr.Textbox(label=\"Email Status / Error\")\n",
        "\n",
        "    # When clicked, run process_email_gradio using travel_output plus the three email fields\n",
        "    email_button.click(\n",
        "        fn=process_email_gradio,\n",
        "        inputs=[travel_output, sender_input, receiver_input, subject_input],\n",
        "        outputs=email_status\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BooZ2A7Vg0Ti",
        "outputId": "6b06f50d-5dce-46b8-e014-7d5131db3e65"
      },
      "id": "BooZ2A7Vg0Ti",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.32.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.6.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.10.2 (from gradio)\n",
            "  Downloading gradio_client-1.10.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.47.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.32.1-py3-none-any.whl (54.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.2-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m134.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.6.0-py3-none-any.whl (5.5 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.6.0 gradio-5.32.1 gradio-client-1.10.2 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.12 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch Gradio app\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(server_name=\"0.0.0.0\", share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "y5_UXS9DiVhv",
        "outputId": "992af497-d7cf-4f04-e9b8-64ab4a2adacf"
      },
      "id": "y5_UXS9DiVhv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ec613affd346f76fcb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ec613affd346f76fcb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sendgrid import SendGridAPIClient\n",
        "from sendgrid.helpers.mail import Mail\n",
        "\n",
        "message = Mail(\n",
        "    from_email=\"rajatdandekar@vizuara.com\",\n",
        "    to_emails=\"recipient@example.com\",\n",
        "    subject=\"SendGrid Permission Test\",\n",
        "    html_content=\"<strong>If you see this, permission is fixed!</strong>\"\n",
        ")\n",
        "\n",
        "try:\n",
        "    sg = SendGridAPIClient(os.environ[\"SENDGRID_API_KEY\"])\n",
        "    resp = sg.send(message)\n",
        "    print(\"Response status:\", resp.status_code)  # Expect 202, not 403\n",
        "except Exception as e:\n",
        "    print(\"SendGrid error:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujS-5yQbq6DB",
        "outputId": "7dde1ffe-9158-47ec-dcfe-507f9dd77255"
      },
      "id": "ujS-5yQbq6DB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SendGrid error: HTTP Error 403: Forbidden\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}